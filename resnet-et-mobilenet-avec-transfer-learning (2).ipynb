{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313},{"sourceId":559939,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":424539,"modelId":442028},{"sourceId":560175,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":424666,"modelId":442155}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# chargement des bibliothéques","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks\nfrom sklearn.utils import class_weight\nimport shutil\nimport time\nimport json\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import models, optimizers\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T14:49:12.270750Z","iopub.execute_input":"2025-09-10T14:49:12.271261Z","iopub.status.idle":"2025-09-10T14:49:12.280301Z","shell.execute_reply.started":"2025-09-10T14:49:12.271237Z","shell.execute_reply":"2025-09-10T14:49:12.279626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\n\ndataset_path = '/kaggle/input/new-plant-diseases-dataset/'\n\n# Explore the directory structure\nfor root, dirs, files in os.walk(dataset_path):\n    level = root.replace(dataset_path, '').count(os.sep)\n    indent = ' ' * 2 * level\n    print(f\"{indent}{os.path.basename(root)}/\")\n    subindent = ' ' * 2 * (level + 1)\n    for file in files[:5]:  # Show first 5 files\n        print(f\"{subindent}{file}\")\n    if len(files) > 5:\n        print(f\"{subindent}... and {len(files) - 5} more files\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:17:13.133121Z","iopub.execute_input":"2025-09-08T10:17:13.133363Z","iopub.status.idle":"2025-09-08T10:20:50.743066Z","shell.execute_reply.started":"2025-09-08T10:17:13.133339Z","shell.execute_reply":"2025-09-08T10:20:50.742421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Chemin de base\nbase_path = '/kaggle/input/new-plant-diseases-dataset/'\n\n# Chercher les dossiers train, valid, test\ndef find_data_dirs(base_path):\n    train_dir = None\n    valid_dir = None\n    test_dir = None\n    \n    # Parcourir tous les sous-dossiers\n    for root, dirs, files in os.walk(base_path):\n        for d in dirs:\n            if 'train' in d.lower():\n                train_dir = os.path.join(root, d)\n            elif 'valid' in d.lower() or 'val' in d.lower():\n                valid_dir = os.path.join(root, d)\n            elif 'test' in d.lower():\n                test_dir = os.path.join(root, d)\n    \n    return train_dir, valid_dir, test_dir\n\n# Trouver les dossiers automatiquement\ntrain_dir, valid_dir, test_dir = find_data_dirs(base_path)\n\nprint(f\"Train directory: {train_dir}\")\nprint(f\"Valid directory: {valid_dir}\")\nprint(f\"Test directory: {test_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:25:30.866034Z","iopub.execute_input":"2025-09-08T10:25:30.866506Z","iopub.status.idle":"2025-09-08T10:26:18.244833Z","shell.execute_reply.started":"2025-09-08T10:25:30.866482Z","shell.execute_reply":"2025-09-08T10:26:18.244153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Vérifier que les dossiers existent\nimport os\nprint(\"Vérification des dossiers:\")\nprint(f\"Train dir exists: {os.path.exists(train_dir)}\")\nprint(f\"Valid dir exists: {os.path.exists(valid_dir)}\")\nprint(f\"Test dir exists: {os.path.exists(test_dir)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:26:32.493397Z","iopub.execute_input":"2025-09-08T10:26:32.493692Z","iopub.status.idle":"2025-09-08T10:26:32.499367Z","shell.execute_reply.started":"2025-09-08T10:26:32.493672Z","shell.execute_reply":"2025-09-08T10:26:32.498713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nums = {}\nfor dir_name in sorted(os.listdir(train_dir)):\n    class_dir = os.path.join(train_dir, dir_name)\n    if os.path.isdir(class_dir):\n        nums[dir_name] = len(os.listdir(class_dir))\n# Total number of images\nn_train = sum(nums.values())\nprint(f\"There are {n_train} images for training\")\n# Convert to DataFrame and sort index\nimg_per_class = pd.DataFrame.from_dict(nums, orient='index', columns=[\"no. of images\"])\nimg_per_class.index.name = \"class name\"\nimg_per_class = img_per_class.sort_index()\nimg_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:26:42.381785Z","iopub.execute_input":"2025-09-08T10:26:42.382053Z","iopub.status.idle":"2025-09-08T10:26:42.448182Z","shell.execute_reply.started":"2025-09-08T10:26:42.382032Z","shell.execute_reply":"2025-09-08T10:26:42.447616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip('horizontal'), # flip horizontal\n    tf.keras.layers.RandomRotation(0.2), # rotated by a random amount between -20% and +20% of a full circle\n    tf.keras.layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)), # zoom in/out by up to 20%\n    tf.keras.layers.RandomContrast(factor=0.2) # Adjust contrast by up to 20%\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T14:49:20.657348Z","iopub.execute_input":"2025-09-10T14:49:20.657604Z","iopub.status.idle":"2025-09-10T14:49:20.673867Z","shell.execute_reply.started":"2025-09-10T14:49:20.657586Z","shell.execute_reply":"2025-09-10T14:49:20.673261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T14:49:24.288553Z","iopub.execute_input":"2025-09-10T14:49:24.289087Z","iopub.status.idle":"2025-09-10T14:49:24.481563Z","shell.execute_reply.started":"2025-09-10T14:49:24.289066Z","shell.execute_reply":"2025-09-10T14:49:24.480709Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# split_dataset ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nweights_path = \"/kaggle/input/resnet50/keras/default/1/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n# =========================\n# 1) Lister fichiers + labels (depuis TRAIN_DIR)\n# =========================\nimport os, pathlib, numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport tensorflow as tf\n\nSEED = 123\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\nTRAIN_DIR = \"/kaggle/input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train\"\n\n# Collecte de tous les fichiers avec leur label (nom du dossier parent)\nrows = []\nfor class_dir in sorted(os.listdir(TRAIN_DIR)):\n    cpath = os.path.join(TRAIN_DIR, class_dir)\n    if not os.path.isdir(cpath):\n        continue\n    for fp in pathlib.Path(cpath).glob(\"*\"):\n        if fp.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n            rows.append({\"filepath\": str(fp), \"label\": class_dir})\n\ndf = pd.DataFrame(rows)\nprint(f\"Total images (train source): {len(df)} | Classes: {df['label'].nunique()}\")\n\n# Classes triées et mapping label->index (à réutiliser partout)\nclass_names = sorted(df[\"label\"].unique().tolist())\nname_to_idx = {name: i for i, name in enumerate(class_names)}\ndf[\"y\"] = df[\"label\"].map(name_to_idx)\n\n# =========================\n# 2) Split stratifié: train/val/test = 80/10/10\n# =========================\n# d’abord train_temp / test (10%)\nsss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=SEED)\ntrain_temp_idx, test_idx = next(sss1.split(df[\"filepath\"], df[\"y\"]))\ndf_train_temp = df.iloc[train_temp_idx].reset_index(drop=True)\ndf_test       = df.iloc[test_idx].reset_index(drop=True)\n\n# puis train / val (12.5% de train_temp ≈ 0.125 * 0.90 = 0.1125 ~ 10% du total)\nval_fraction_in_temp = 0.125\nsss2 = StratifiedShuffleSplit(n_splits=1, test_size=val_fraction_in_temp, random_state=SEED)\ntrain_idx, val_idx = next(sss2.split(df_train_temp[\"filepath\"], df_train_temp[\"y\"]))\ndf_train = df_train_temp.iloc[train_idx].reset_index(drop=True)\ndf_val   = df_train_temp.iloc[val_idx].reset_index(drop=True)\n\nprint(f\"Split -> train: {len(df_train)} | val: {len(df_val)} | test: {len(df_test)}\")\n\n# =========================\n# 3) Fonctions utilitaires pour tf.data\n# =========================\ndef make_ds(filepaths, labels, img_size=IMG_SIZE, batch_size=BATCH_SIZE, training=False):\n    paths_ds = tf.data.Dataset.from_tensor_slices(filepaths)\n    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n\n    def load_and_preprocess(path, y):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n        img = tf.image.resize(img, img_size)\n        img = tf.cast(img, tf.float32)\n        img = tf.keras.applications.resnet.preprocess_input(img)\n        return img, y\n\n    ds = tf.data.Dataset.zip((paths_ds, labels_ds))\n    ds = ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n    if training:\n        ds = ds.shuffle(buffer_size=8 * batch_size, seed=SEED, reshuffle_each_iteration=True)\n    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n    return ds\n\ntrain_ds_new = make_ds(df_train[\"filepath\"].values, df_train[\"y\"].values, training=True)\nval_ds_new   = make_ds(df_val[\"filepath\"].values,   df_val[\"y\"].values,   training=False)\ntest_ds_new  = make_ds(df_test[\"filepath\"].values,  df_test[\"y\"].values,  training=False)\n\nprint(\"Datasets prêts. Exemple shapes:\")\nfor imgs, ys in train_ds_new.take(1):\n    print(\"train batch:\", imgs.shape, ys.shape)\n\n# Pour info : class_names est le vocabulaire à réutiliser\nprint(\"Nombre de classes:\", len(class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T14:49:29.482547Z","iopub.execute_input":"2025-09-10T14:49:29.483088Z","iopub.status.idle":"2025-09-10T14:49:30.748018Z","shell.execute_reply.started":"2025-09-10T14:49:29.483052Z","shell.execute_reply":"2025-09-10T14:49:30.747287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# resnet avec learning rate = 0.00001","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom keras.callbacks import EarlyStopping\n\nbase_model = tf.keras.applications.ResNet50(\n    include_top=False,\n    weights=weights_path,      # on pointe vers le fichier uploadé\n    input_shape=(224, 224, 3)\n)\nbase_model.trainable = False\nbase_model.trainable = False\n\n# Unfreeze some layers of the base model for fine-tuning\nfor layer in base_model.layers[-10:]:\n    layer.trainable = True\n    inputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = tf.keras.applications.resnet.preprocess_input(x)\nx = base_model(x, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(38)(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n# Define EarlyStopping callback\nearly_stopping = callbacks.EarlyStopping(patience=3)\n\n# Train the model with early stopping\nhistory = model.fit(\n    train_ds_new,\n    validation_data=val_ds_new,\n    epochs=10,\n    callbacks=[early_stopping],     # EarlyStopping, ModelCheckpoint, etc.\n    class_weight=None    # (optionnel) recalculer avec df_train['y'] si classes déséquilibrées\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T10:50:38.148853Z","iopub.execute_input":"2025-09-08T10:50:38.149619Z","iopub.status.idle":"2025-09-08T11:20:16.496771Z","shell.execute_reply.started":"2025-09-08T10:50:38.149570Z","shell.execute_reply":"2025-09-08T11:20:16.496145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15,4))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T16:44:27.652970Z","iopub.execute_input":"2025-09-10T16:44:27.653244Z","iopub.status.idle":"2025-09-10T16:44:28.080786Z","shell.execute_reply.started":"2025-09-10T16:44:27.653225Z","shell.execute_reply":"2025-09-10T16:44:28.080118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom tensorflow.keras.utils import to_categorical\n\n# -----------------------------\n# 1️⃣ Extraire les images et labels du dataset de validation\n# -----------------------------\nX_val_list, y_val_list = [], []\n\nfor images, labels in val_ds_new:\n    X_val_list.append(images.numpy())\n    y_val_list.append(labels.numpy())\n\nX_val = np.concatenate(X_val_list, axis=0)\ny_val_int = np.concatenate(y_val_list, axis=0)  # labels entiers\n\n# Convertir en one-hot\nn_classes = len(np.unique(y_val_int))\ny_val = to_categorical(y_val_int, num_classes=n_classes)\n\n# -----------------------------\n# 2️⃣ Prédictions du modèle\n# -----------------------------\ny_pred = tf.nn.softmax(model.predict(X_val)).numpy()  # shape (N, n_classes)\n\n# -----------------------------\n# 3️⃣ ROC Curve One-vs-Rest pour chaque classe\nplt.figure(figsize=(8,8))\n\nfor i in range(n_classes):\n    fpr, tpr, _ = roc_curve(y_val[:, i], y_pred[:, i])\n    roc_auc_i = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc_i:.2f})')\n\nplt.plot([0, 1], [0, 1], 'r--', lw=2)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve (OvR) per Class')\nplt.legend(loc='lower right')\nplt.show()\n\n# -----------------------------\n# 4️⃣ Score ROC-AUC global (OvR)\n# -----------------------------\nfrom sklearn.metrics import roc_auc_score\nroc_auc_global = roc_auc_score(y_val, y_pred, multi_class='ovr')\nprint(\"ROC-AUC Score (OvR, Validation) :\", roc_auc_global)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# resnet avec learning rate = 0.001","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import callbacks\n\n# Base ResNet50\nbase_model = ResNet50(\n    include_top=False,\n    weights=weights_path,   # chemin vers tes poids\n    input_shape=(224, 224, 3)\n)\nbase_model.trainable = False\n\n# Débloquer les 10 dernières couches pour fine-tuning\nfor layer in base_model.layers[-10:]:\n    layer.trainable = True\n\n# Construction du modèle\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = tf.keras.applications.resnet.preprocess_input(x)\nx = base_model(x, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(512, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(38, activation='softmax')(x)  # softmax pour classification multi-classes\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n# Compilation\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # car softmax activé\n    metrics=['accuracy']\n)\n\n# Callbacks : EarlyStopping + sauvegarde du meilleur modèle\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,                # plus de tolérance\n    min_delta=0.001,            # ignore les petites fluctuations\n    restore_best_weights=True   # remet les meilleurs poids\n)\n\ncheckpoint = callbacks.ModelCheckpoint(\n    filepath=\"best_resnet50_model.keras\",\n    monitor=\"val_loss\",\n    save_best_only=True,\n    mode=\"min\"\n)\n\n# Entraînement\nhistory = model.fit(\n    train_ds_new,\n    validation_data=val_ds_new,\n    epochs=10,                   # ✅ autoriser plus d’époques\n    callbacks=[early_stopping, checkpoint],\n    class_weight=None\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T16:14:19.693634Z","iopub.execute_input":"2025-09-10T16:14:19.693913Z","iopub.status.idle":"2025-09-10T16:44:20.211117Z","shell.execute_reply.started":"2025-09-10T16:14:19.693894Z","shell.execute_reply":"2025-09-10T16:44:20.210264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15,4))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom tensorflow.keras.utils import to_categorical\n\n# -----------------------------\n# 1️⃣ Extraire les images et labels du dataset de validation\n# -----------------------------\nX_val_list, y_val_list = [], []\n\nfor images, labels in val_ds_new:\n    X_val_list.append(images.numpy())\n    y_val_list.append(labels.numpy())\n\nX_val = np.concatenate(X_val_list, axis=0)\ny_val_int = np.concatenate(y_val_list, axis=0)  # labels entiers\n\n# Convertir en one-hot\nn_classes = len(np.unique(y_val_int))\ny_val = to_categorical(y_val_int, num_classes=n_classes)\n\n# -----------------------------\n# 2️⃣ Prédictions du modèle\n# -----------------------------\ny_pred = tf.nn.softmax(model.predict(X_val)).numpy()  # shape (N, n_classes)\n\n# -----------------------------\n# 3️⃣ ROC Curve One-vs-Rest pour chaque classe\n# -----------------------------\nplt.figure(figsize=(8,8))\n\nfor i in range(n_classes):\n    fpr, tpr, _ = roc_curve(y_val[:, i], y_pred[:, i])\n    roc_auc_i = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {roc_auc_i:.2f})')\n\nplt.plot([0, 1], [0, 1], 'r--', lw=2)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve (OvR) per Class')\nplt.legend(loc='lower right')\nplt.show()\n\n# -----------------------------\n# 4️⃣ Score ROC-AUC global (OvR)\n# -----------------------------\nfrom sklearn.metrics import roc_auc_score\nroc_auc_global = roc_auc_score(y_val, y_pred, multi_class='ovr')\nprint(\"ROC-AUC Score (OvR, Validation) :\", roc_auc_global)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-10T16:53:20.817244Z","iopub.execute_input":"2025-09-10T16:53:20.817820Z","iopub.status.idle":"2025-09-10T16:54:10.320250Z","shell.execute_reply.started":"2025-09-10T16:53:20.817798Z","shell.execute_reply":"2025-09-10T16:54:10.319411Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report\n)\n\n# Predict on validation set\ny_true = []\ny_pred = []\n\nfor images, labels in val_ds_new:\n    predictions = model.predict(images, verbose=0)\n    y_true.extend(labels.numpy())\n    y_pred.extend(np.argmax(predictions, axis=1))\n\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrecall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\ncm = confusion_matrix(y_true, y_pred)\n\n# Print metrics\nprint(\"📊 Validation Evaluation Metrics:\")\nprint(f\"Accuracy : {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1-score : {f1:.4f}\")\nprint()\n\n# Classification report\nprint(\"🧾 Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix (Validation Set)')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:23:34.057704Z","iopub.execute_input":"2025-09-08T11:23:34.057974Z","iopub.status.idle":"2025-09-08T11:24:15.651153Z","shell.execute_reply.started":"2025-09-08T11:23:34.057955Z","shell.execute_reply":"2025-09-08T11:24:15.650451Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# test ResNet50","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\nimport numpy as np, seaborn as sns, matplotlib.pyplot as plt\n\ntest_loss, test_acc = model.evaluate(test_ds_new, verbose=1)\nprint(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")\ny_true, y_pred = [], []\nfor images, labels in test_ds_new:\n    logits = model.predict(images, verbose=0)\n    preds = np.argmax(logits, axis=1)\n    y_true.extend(labels.numpy().tolist())\n    y_pred.extend(preds.tolist())\n\ny_true = np.array(y_true); y_pred = np.array(y_pred)\n\nacc = accuracy_score(y_true, y_pred)\nprec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\nprint(f\"\\n📊 Test — Acc:{acc:.4f}  Prec:{prec:.4f}  Rec:{rec:.4f}  F1:{f1:.4f}\\n\")\nprint(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(12,10))\nsns.heatmap(cm, cmap=\"Blues\", cbar=False,\n            xticklabels=class_names, yticklabels=class_names)\nplt.title(\"Confusion Matrix — Test\"); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\nplt.tight_layout(); plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:25:46.284067Z","iopub.execute_input":"2025-09-08T11:25:46.284335Z","iopub.status.idle":"2025-09-08T11:26:37.159743Z","shell.execute_reply.started":"2025-09-08T11:25:46.284315Z","shell.execute_reply":"2025-09-08T11:26:37.159030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Nombre de classes\nn_classes = len(class_names)  \n\nclass_samples = {}\nX_test_aug = []\ntrue_labels_idx = []\ntrue_labels_name = []\n\n# -----------------------------\n# 1️⃣ Sélectionner 1 image par classe depuis val_ds_new\n# -----------------------------\nfor batch in val_ds_new:\n    images, labels = batch\n    labels_idx = labels.numpy() if len(labels.shape) == 1 else np.argmax(labels.numpy(), axis=1)\n\n    for i, label in enumerate(labels_idx):\n        if label not in class_samples:  # première image trouvée pour cette classe\n            class_samples[label] = True\n            X_test_aug.append(images[i].numpy())\n            true_labels_idx.append(label)              # indice réel\n            true_labels_name.append(class_names[label]) # nom réel\n    if len(class_samples) == n_classes:\n        break\n\nX_test_aug = np.stack(X_test_aug, axis=0)\nprint(\"Images test simulées :\", X_test_aug.shape)\n\n# -----------------------------\n# 2️⃣ Faire les prédictions\n# -----------------------------\ny_pred_proba = model.predict(X_test_aug, verbose=0)\npred_classes_idx = np.argmax(y_pred_proba, axis=1)\npred_classes_name = [class_names[i] for i in pred_classes_idx]\n\n# -----------------------------\n# 3️⃣ Créer le DataFrame final\n# -----------------------------\ndf_pred = pd.DataFrame({\n    \"true_class_idx\": true_labels_idx,\n    \"true_class\": true_labels_name,\n    \"predicted_class_idx\": pred_classes_idx,\n    \"predicted_class\": pred_classes_name\n})\n\n# Sauvegarde CSV\noutput_csv = \"predictions_test_simulated.csv\"\ndf_pred.to_csv(output_csv, index=False)\n\nprint(f\"CSV final généré : {output_csv}\")\nprint(df_pred.head(38).to_markdown(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:48:18.123351Z","iopub.execute_input":"2025-09-08T11:48:18.124068Z","iopub.status.idle":"2025-09-08T11:48:18.669039Z","shell.execute_reply.started":"2025-09-08T11:48:18.124041Z","shell.execute_reply":"2025-09-08T11:48:18.668260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Charger ton CSV\ndf_pred = pd.read_csv(\"predictions_test_simulated.csv\")\n\n# Garder uniquement colonnes utiles\ndf_compare = df_pred[[\"true_class\", \"predicted_class\"]]\n\n# Affichage clair (markdown par exemple)\nprint(df_compare.head(20).to_markdown(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T11:50:40.560144Z","iopub.execute_input":"2025-09-08T11:50:40.560879Z","iopub.status.idle":"2025-09-08T11:50:40.571414Z","shell.execute_reply.started":"2025-09-08T11:50:40.560846Z","shell.execute_reply":"2025-09-08T11:50:40.570849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet avec learning rate 0.001","metadata":{}},{"cell_type":"code","source":"# Build MobileNetV2 model with transfer learning\ndef build_mobilenet():\n    # Load the pre-trained MobileNetV2 model\n    base_model = MobileNetV2(\n        input_shape=img_size + (3,),\n        include_top=False,\n        weights='/kaggle/input/mobilenet/keras/default/1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n    )\n\n    # Freeze the base model\n    base_model.trainable = False\n\n    # Create the new model\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(256, activation='relu'),  # Increased units\n        layers.BatchNormalization(),            # Batch normalization\n        layers.Dropout(0.5),\n        layers.Dense(256, activation='relu'),  # Additional dense layer\n        layers.BatchNormalization(),            # Batch normalization\n        layers.Dropout(0.5),\n        layers.Dense(train_generator.num_classes, activation='softmax')\n    ])\n\n    # Compile the model\n    model.compile(\n    optimizer=tf.keras.optimizers.adam(learning_rate=1e-3),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)\n    return model\n\n# Create the model\nmobilenet_model = build_mobilenet()\n\n# Display model summary\nmobilenet_model.summary()\n\n# Callbacks\nmobilenet_early_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True\n)\n\nmobilenet_checkpoint = ModelCheckpoint(\n   'mobilenet_model.keras',\n    monitor='val_loss',\n    save_best_only=True\n)\n\n# Train the model\nmobilenet_history = mobilenet_model.fit(\n    train_ds_new,\n    validation_data=val_ds_new,\n    epochs=10,\n    callbacks=[mobilenet_early_stop, mobilenet_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T12:26:52.734474Z","iopub.execute_input":"2025-09-08T12:26:52.735217Z","iopub.status.idle":"2025-09-08T12:39:48.450217Z","shell.execute_reply.started":"2025-09-08T12:26:52.735193Z","shell.execute_reply":"2025-09-08T12:39:48.449615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\nimport seaborn as sns\nimport tensorflow as tf\n\n# -----------------------------\n# 1️⃣ Courbes de Loss et Accuracy\n# -----------------------------\nacc = mobilenet_history.history['accuracy']\nval_acc = mobilenet_history.history['val_accuracy']\nloss = mobilenet_history.history['loss']\nval_loss = mobilenet_history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n\n# -----------------------------\n# 2️⃣ Prédictions sur le validation set\n# -----------------------------\ny_val = []\ny_pred = []\n\nfor batch_x, batch_y in val_ds_new:\n    y_val.append(batch_y)\n    preds = mobilenet_model.predict(batch_x)\n    y_pred.append(preds)\n    \n    # Break the loop if generator is exhausted\n    if len(y_val)*val_ds_new.batch_size >= val_ds_new.samples:\n        break\n\ny_val = np.vstack(y_val)\ny_pred = np.vstack(y_pred)\n\n# Classes vraies et prédictions\ny_true_classes = np.argmax(y_val, axis=1)\ny_pred_classes = np.argmax(y_pred, axis=1)\nclass_names = list(train_ds_new.class_indices.keys())\n\n# -----------------------------\n# 3️⃣ Matrice de confusion\n# -----------------------------\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nplt.figure(figsize=(12,10))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# -----------------------------\n# 4️⃣ Rapport de classification\n# -----------------------------\nreport = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\nprint(\"Classification Report:\\n\")\nprint(report)\n\n# -----------------------------\n# 5️⃣ ROC-AUC Multi-classes (One-vs-Rest)\n# -----------------------------\nroc_auc = roc_auc_score(y_val, y_pred, multi_class='ovr')\nprint(f\"ROC-AUC Score (OvR, Validation): {roc_auc:.4f}\")\n\n# Optionnel : Courbes ROC pour chaque classe\nplt.figure(figsize=(10,10))\nfor i, class_name in enumerate(class_names):\n    fpr, tpr, _ = roc_curve(y_val[:, i], y_pred[:, i])\n    auc_score = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=2, label=f'{class_name} (AUC = {auc_score:.2f})')\n\nplt.plot([0, 1], [0, 1], color='red', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve - Multi-class (OvR)')\nplt.legend(loc='lower right', fontsize='small')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T12:40:09.351135Z","iopub.execute_input":"2025-09-08T12:40:09.351406Z","iopub.status.idle":"2025-09-08T12:43:28.028462Z","shell.execute_reply.started":"2025-09-08T12:40:09.351384Z","shell.execute_reply":"2025-09-08T12:43:28.027807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mobilenet avec learning rate= 0.00001","metadata":{}},{"cell_type":"code","source":"# Étape 1 : Préparer data augmentation\ndata_augmentation = tf.keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.2),\n    layers.RandomZoom(0.2),\n    layers.RandomContrast(0.1),\n])\n\n# Étape 2 : Charger MobileNetV2 (weights ImageNet)\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=img_size + (3,),\n    include_top=False,\n    weights=\"/kaggle/input/mobilenet/keras/default/1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\"\n)\n\nbase_model.trainable = False  # geler pour le warmup\n\n# Étape 3 : Construire modèle\ninputs = layers.Input(shape=img_size + (3,))\nx = data_augmentation(inputs)\nx = tf.keras.applications.mobilenet_v2.preprocess_input(x)\nx = base_model(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation=\"relu\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(train_generator.num_classes, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n# Étape 4 : Compiler\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# Étape 5 : Calcul des poids de classes\nfrom sklearn.utils import class_weight\nimport numpy as np\n\ny_train = np.concatenate([y.numpy() for x, y in train_ds_new], axis=0)\n\n# Calcul des poids de classes équilibrés\nclass_weights = class_weight.compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(y_train),\n    y=y_train\n)\nclass_weights = dict(enumerate(class_weights))\n\n# Étape 6 : Entraînement (warmup)\nhistory = model.fit(\n    train_ds_new,\n    validation_data=val_ds_new,\n    epochs=10,\n    class_weight=class_weights,\n    callbacks=[mobilenet_early_stop, mobilenet_checkpoint]\n)\n\n# Étape 7 : Fine-tuning (débloquer dernier bloc de MobileNetV2)\nbase_model.trainable = True\nfor layer in base_model.layers[:-40]:  # on garde ~40 dernières couches dégelées\n    layer.trainable = False\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nfine_tune_history = model.fit(\n    train_ds_new,\n    validation_data=val_ds_new,\n    epochs=10,\n    class_weight=class_weights,\n    callbacks=[mobilenet_early_stop, mobilenet_checkpoint]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T13:00:55.406207Z","iopub.execute_input":"2025-09-08T13:00:55.406489Z","iopub.status.idle":"2025-09-08T13:36:26.516438Z","shell.execute_reply.started":"2025-09-08T13:00:55.406469Z","shell.execute_reply":"2025-09-08T13:36:26.515678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_training(history, title):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    # Accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'bo-', label='Training acc')\n    plt.plot(epochs, val_acc, 'ro-', label='Validation acc')\n    plt.title(f'Accuracy - {title}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Training loss')\n    plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n    plt.title(f'Loss - {title}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.show()\n\n# Visualiser les deux phases\nplot_training(history, \"Warmup (LR=1e-3)\")\nplot_training(fine_tune_history, \"Fine-tuning (LR=1e-5)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T13:37:04.797264Z","iopub.execute_input":"2025-09-08T13:37:04.798062Z","iopub.status.idle":"2025-09-08T13:37:05.391405Z","shell.execute_reply.started":"2025-09-08T13:37:04.798034Z","shell.execute_reply":"2025-09-08T13:37:05.390768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndef plot_confusion_matrix(model, dataset, title=\"Matrice de confusion\"):\n    \"\"\"\n    Trace la matrice de confusion avec valeurs numériques et noms de classes.\n    \n    Args:\n        model: modèle Keras\n        dataset: tf.data.Dataset (inputs, labels)\n        title: titre du graphique\n    \"\"\"\n    \n    y_true_list = []\n    y_pred_list = []\n\n    # ⚡ Accumuler labels et prédictions batch par batch\n    for x_batch, y_batch in dataset:\n        y_true_list.append(y_batch.numpy())\n        y_pred_probs = model.predict(x_batch, verbose=0)\n        y_pred_batch = np.argmax(y_pred_probs, axis=1)\n        y_pred_list.append(y_pred_batch)\n\n    # Convertir en arrays\n    y_true = np.concatenate(y_true_list, axis=0)\n    y_pred = np.concatenate(y_pred_list, axis=0)\n\n    # Déterminer automatiquement les classes\n    classes = np.unique(y_true)\n    class_names = [f\"Classe {i}\" for i in classes]\n\n    # Matrice de confusion (valeurs entières)\n    cm = confusion_matrix(y_true, y_pred)\n\n    # 🔹 Affichage avec valeurs et noms de classes\n    plt.figure(figsize=(15, 12))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Prédictions')\n    plt.ylabel('Vérités terrain')\n    plt.title(f\"{title}\")\n    plt.show()\n\n    # Rapport détaillé\n    print(f\"\\n=== Rapport de classification - {title} ===\")\n    print(classification_report(y_true, y_pred, target_names=class_names))\n# ⚡ Matrice après Warmup\nplot_confusion_matrix(mobilenet_model, val_ds_new, \"Phase Warmup (LR=1e-3)\")\n\n# ⚡ Matrice après Fine-tuning\nplot_confusion_matrix(mobilenet_model, val_ds_new, \"Phase Fine-tuning (LR=1e-5)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T13:56:53.658903Z","iopub.execute_input":"2025-09-08T13:56:53.659494Z","iopub.status.idle":"2025-09-08T13:57:50.032281Z","shell.execute_reply.started":"2025-09-08T13:56:53.659471Z","shell.execute_reply":"2025-09-08T13:57:50.031696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\ndef plot_roc_auc(model, dataset, n_classes, title=\"ROC-AUC\"):\n    \"\"\"\n    Affiche le ROC-AUC pour un dataset TensorFlow en mode multi-classes.\n    \n    Args:\n        model: modèle Keras\n        dataset: tf.data.Dataset (inputs, labels)\n        n_classes: nombre de classes\n        title: titre du graphique\n    \"\"\"\n    \n    y_true_list = []\n    y_pred_list = []\n\n    # ⚡ Accumuler les labels et les prédictions batch par batch\n    for x_batch, y_batch in dataset:\n        y_true_list.append(y_batch.numpy())\n        y_pred_batch = model.predict(x_batch, verbose=0)\n        y_pred_list.append(y_pred_batch)\n\n    # Convertir en arrays\n    y_true = np.concatenate(y_true_list, axis=0)\n    y_pred_probs = np.concatenate(y_pred_list, axis=0)\n\n    # Vérifier les shapes pour éviter l'erreur\n    print(f\"y_true.shape = {y_true.shape}, y_pred_probs.shape = {y_pred_probs.shape}\")\n\n    # Binariser les labels pour le ROC-AUC multi-classes\n    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n\n    # Calcul du ROC-AUC\n    roc_auc_macro = roc_auc_score(y_true_bin, y_pred_probs, average=\"macro\", multi_class=\"ovr\")\n    roc_auc_micro = roc_auc_score(y_true_bin, y_pred_probs, average=\"micro\", multi_class=\"ovr\")\n\n    print(f\"\\n=== {title} ===\")\n    print(f\"ROC-AUC Macro: {roc_auc_macro:.4f}\")\n    print(f\"ROC-AUC Micro: {roc_auc_micro:.4f}\")\n\n    # Tracer 3 courbes ROC aléatoires\n    plt.figure(figsize=(8, 6))\n    for i in np.random.choice(range(n_classes), size=max(3, n_classes), replace=False):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n        plt.plot(fpr, tpr, label=f\"Classe {i} (AUC={auc(fpr, tpr):.2f})\")\n\n    plt.plot([0, 1], [0, 1], \"k--\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(f\"ROC Curve - {title}\")\n    plt.legend()\n    plt.show()\n# Définir correctement le nombre de classes\nn_classes = 38  # Remplace 38 par ton nombre réel de classes si nécessaire\n\n# ⚡ ROC-AUC après Warmup\nplot_roc_auc(mobilenet_model, val_ds_new, n_classes, \"Phase Warmup (LR=1e-3)\")\n\n# ⚡ ROC-AUC après Fine-tuning\nplot_roc_auc(mobilenet_model, val_ds_new, n_classes, \"Phase Fine-tuning (LR=1e-5)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T13:48:35.415746Z","iopub.execute_input":"2025-09-08T13:48:35.416354Z","iopub.status.idle":"2025-09-08T13:49:29.304037Z","shell.execute_reply.started":"2025-09-08T13:48:35.416334Z","shell.execute_reply":"2025-09-08T13:49:29.303235Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# test MobileNet","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nimport numpy as np\n\n# Accumuler les vrais labels et les prédictions\ny_true_list = []\ny_pred_list = []\n\nfor x_batch, y_batch in val_ds_new:\n    y_true_list.append(y_batch.numpy())\n    y_pred_batch = np.argmax(mobilenet_model.predict(x_batch, verbose=0), axis=1)\n    y_pred_list.append(y_pred_batch)\n\ny_true = np.concatenate(y_true_list, axis=0)\ny_pred = np.concatenate(y_pred_list, axis=0)\n\n# Calcul des métriques globales\nacc = accuracy_score(y_true, y_pred)\nprec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\nrec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\nf1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n\nprint(f\"\\n📊 Test — Acc:{acc:.4f}  Prec:{prec:.4f}  Rec:{rec:.4f}  F1:{f1:.4f}\\n\")\n\n# Générer automatiquement les noms de classes pour éviter le mismatch\nclasses = np.unique(y_true)\nclass_names = [f\"Classe {i}\" for i in classes]\n\n# Rapport détaillé\nprint(classification_report(y_true, y_pred, labels=classes, target_names=class_names, zero_division=0))\n\n# Matrice de confusion\ncm = confusion_matrix(y_true, y_pred, labels=classes)\n\n# 🔹 Affichage\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15, 12))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Prédictions')\nplt.ylabel('Vérités terrain')\nplt.title('Matrice de confusion complète')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T14:04:05.022125Z","iopub.execute_input":"2025-09-08T14:04:05.023013Z","iopub.status.idle":"2025-09-08T14:04:32.513775Z","shell.execute_reply.started":"2025-09-08T14:04:05.022988Z","shell.execute_reply":"2025-09-08T14:04:32.512910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Nombre de classes\nn_classes = len(class_names)  \n\nclass_samples = {}\nX_test_aug = []\ntrue_labels_idx = []\ntrue_labels_name = []\n\n# -----------------------------\n# 1️⃣ Sélectionner 1 image par classe depuis val_ds_new\n# -----------------------------\nfor batch in val_ds_new:\n    images, labels = batch\n    labels_idx = labels.numpy() if len(labels.shape) == 1 else np.argmax(labels.numpy(), axis=1)\n\n    for i, label in enumerate(labels_idx):\n        if label not in class_samples:  # première image trouvée pour cette classe\n            class_samples[label] = True\n            X_test_aug.append(images[i].numpy())\n            true_labels_idx.append(label)              # indice réel\n            true_labels_name.append(class_names[label]) # nom réel\n    if len(class_samples) == n_classes:\n        break\nX_test_aug = np.stack(X_test_aug, axis=0)\nprint(\"Images test simulées :\", X_test_aug.shape)\n\n# -----------------------------\n# 2️⃣ Faire les prédictions\n# -----------------------------\ny_pred_proba = model.predict(X_test_aug, verbose=0)\npred_classes_idx = np.argmax(y_pred_proba, axis=1)\npred_classes_name = [class_names[i] for i in pred_classes_idx]\n\n# -----------------------------\n# 3️⃣ Créer le DataFrame final\n# -----------------------------\ndf_pred = pd.DataFrame({\n    \"true_class_idx\": true_labels_idx,\n    \"true_class\": true_labels_name,\n    \"predicted_class_idx\": pred_classes_idx,\n    \"predicted_class\": pred_classes_name\n})\n\n# Sauvegarde CSV\noutput_csv = \"predictions_test_simulated.csv\"\ndf_pred.to_csv(output_csv, index=False)\n\nprint(f\"CSV final généré : {output_csv}\")\nprint(df_pred.head(38).to_markdown(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T14:05:45.402812Z","iopub.execute_input":"2025-09-08T14:05:45.403392Z","iopub.status.idle":"2025-09-08T14:05:46.142441Z","shell.execute_reply.started":"2025-09-08T14:05:45.403367Z","shell.execute_reply":"2025-09-08T14:05:46.141752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}